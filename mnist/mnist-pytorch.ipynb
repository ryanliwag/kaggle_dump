{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        tensor = torch.from_numpy(sample[\"image\"])\n",
    "        \n",
    "        return {\"image\":tensor}\n",
    "\n",
    "class mnist_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        \n",
    "        csv_file =\n",
    "        self.targets = t \n",
    "        self.root_folder = root_folder\n",
    "        self.image_list = self.get_image_list()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.root_folder, self.image_list[idx])\n",
    "        img = Image.open(img_name)\n",
    "        \n",
    "        \n",
    "        sample = {'image':np.asarray(img)}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.asarray(trains[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = trains.drop(columns=[\"label\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=variables[0].reshape(28, 28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x233c7b41eb8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object does not appear to be a 8-bit string path or a Python file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-720bf4afc059>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2150\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object does not appear to be a 8-bit string path or a Python file-like object"
     ]
    }
   ],
   "source": [
    "plt.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PIL.Image' from 'C:\\\\Users\\\\ryan.joshua.h.liwag\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\PIL\\\\Image.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist_dataset(root_folder=\"trainingSample/\", transform=(ToTensor()))\n",
    "\n",
    "dataloader = DataLoader(mnist, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][\"image\"].reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 28, 28])\n",
      "1 torch.Size([4, 28, 28])\n",
      "2 torch.Size([4, 28, 28])\n",
      "3 torch.Size([4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_size, D_in, H_layers, D_out = 4, 784, 1000, 10\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched['image'].size())\n",
    "    \n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34189644.0\n",
      "1 29711042.0\n",
      "2 25080740.0\n",
      "3 18660142.0\n",
      "4 12330950.0\n",
      "5 7497069.0\n",
      "6 4546526.0\n",
      "7 2902201.25\n",
      "8 2006440.75\n",
      "9 1492909.875\n",
      "10 1173900.875\n",
      "11 957528.6875\n",
      "12 799244.8125\n",
      "13 677228.875\n",
      "14 579924.8125\n",
      "15 500347.90625\n",
      "16 434364.65625\n",
      "17 379013.25\n",
      "18 332180.4375\n",
      "19 292356.6875\n",
      "20 258268.796875\n",
      "21 228920.875\n",
      "22 203582.75\n",
      "23 181601.8125\n",
      "24 162425.640625\n",
      "25 145649.0625\n",
      "26 130930.4453125\n",
      "27 117981.171875\n",
      "28 106551.515625\n",
      "29 96440.2890625\n",
      "30 87453.6875\n",
      "31 79450.4375\n",
      "32 72303.5390625\n",
      "33 65906.796875\n",
      "34 60172.09375\n",
      "35 55019.1796875\n",
      "36 50379.0234375\n",
      "37 46193.25\n",
      "38 42412.546875\n",
      "39 38990.953125\n",
      "40 35888.5859375\n",
      "41 33071.70703125\n",
      "42 30509.693359375\n",
      "43 28177.359375\n",
      "44 26056.974609375\n",
      "45 24121.87109375\n",
      "46 22351.509765625\n",
      "47 20729.916015625\n",
      "48 19243.84765625\n",
      "49 17879.345703125\n",
      "50 16626.712890625\n",
      "51 15475.47265625\n",
      "52 14414.658203125\n",
      "53 13436.5048828125\n",
      "54 12533.4931640625\n",
      "55 11699.3125\n",
      "56 10928.251953125\n",
      "57 10214.3896484375\n",
      "58 9553.46875\n",
      "59 8940.7294921875\n",
      "60 8371.9814453125\n",
      "61 7843.9423828125\n",
      "62 7353.1083984375\n",
      "63 6896.76416015625\n",
      "64 6472.0390625\n",
      "65 6076.7578125\n",
      "66 5708.359375\n",
      "67 5364.94189453125\n",
      "68 5044.3974609375\n",
      "69 4745.1396484375\n",
      "70 4465.650390625\n",
      "71 4204.51025390625\n",
      "72 3960.226806640625\n",
      "73 3731.54345703125\n",
      "74 3517.3232421875\n",
      "75 3316.780517578125\n",
      "76 3128.777587890625\n",
      "77 2952.497314453125\n",
      "78 2787.240966796875\n",
      "79 2632.134521484375\n",
      "80 2486.445556640625\n",
      "81 2349.6083984375\n",
      "82 2220.99853515625\n",
      "83 2100.126953125\n",
      "84 1986.477783203125\n",
      "85 1879.52001953125\n",
      "86 1778.85205078125\n",
      "87 1684.03369140625\n",
      "88 1594.7559814453125\n",
      "89 1510.616943359375\n",
      "90 1431.3271484375\n",
      "91 1356.5469970703125\n",
      "92 1286.0108642578125\n",
      "93 1219.4510498046875\n",
      "94 1156.6087646484375\n",
      "95 1097.274658203125\n",
      "96 1041.228271484375\n",
      "97 988.2658081054688\n",
      "98 938.1917724609375\n",
      "99 890.8614501953125\n",
      "100 846.1303100585938\n",
      "101 803.79736328125\n",
      "102 763.72509765625\n",
      "103 725.7911987304688\n",
      "104 689.8935546875\n",
      "105 655.9143676757812\n",
      "106 623.709716796875\n",
      "107 593.2122192382812\n",
      "108 564.3031005859375\n",
      "109 536.9000244140625\n",
      "110 510.9093017578125\n",
      "111 486.2614440917969\n",
      "112 462.8875427246094\n",
      "113 440.7030029296875\n",
      "114 419.6595458984375\n",
      "115 399.67376708984375\n",
      "116 380.71063232421875\n",
      "117 362.6993103027344\n",
      "118 345.580810546875\n",
      "119 329.3226013183594\n",
      "120 313.87725830078125\n",
      "121 299.19500732421875\n",
      "122 285.2412109375\n",
      "123 271.97613525390625\n",
      "124 259.357177734375\n",
      "125 247.35897827148438\n",
      "126 235.95352172851562\n",
      "127 225.09669494628906\n",
      "128 214.7640380859375\n",
      "129 204.9366455078125\n",
      "130 195.5785675048828\n",
      "131 186.66827392578125\n",
      "132 178.18898010253906\n",
      "133 170.109130859375\n",
      "134 162.4168243408203\n",
      "135 155.09259033203125\n",
      "136 148.11154174804688\n",
      "137 141.45994567871094\n",
      "138 135.12066650390625\n",
      "139 129.07876586914062\n",
      "140 123.3218994140625\n",
      "141 117.82984924316406\n",
      "142 112.59391784667969\n",
      "143 107.60272979736328\n",
      "144 102.84452819824219\n",
      "145 98.30551147460938\n",
      "146 93.97576904296875\n",
      "147 89.84371948242188\n",
      "148 85.90249633789062\n",
      "149 82.13951873779297\n",
      "150 78.55042266845703\n",
      "151 75.12311553955078\n",
      "152 71.8533935546875\n",
      "153 68.73135375976562\n",
      "154 65.75033569335938\n",
      "155 62.90406799316406\n",
      "156 60.18311309814453\n",
      "157 57.586483001708984\n",
      "158 55.104698181152344\n",
      "159 52.73581314086914\n",
      "160 50.47272491455078\n",
      "161 48.31085205078125\n",
      "162 46.24604034423828\n",
      "163 44.27210235595703\n",
      "164 42.385677337646484\n",
      "165 40.58192825317383\n",
      "166 38.85784912109375\n",
      "167 37.20945358276367\n",
      "168 35.633907318115234\n",
      "169 34.12626266479492\n",
      "170 32.686180114746094\n",
      "171 31.30869483947754\n",
      "172 29.99111557006836\n",
      "173 28.7301025390625\n",
      "174 27.52462387084961\n",
      "175 26.370967864990234\n",
      "176 25.267078399658203\n",
      "177 24.21082305908203\n",
      "178 23.200420379638672\n",
      "179 22.233112335205078\n",
      "180 21.308040618896484\n",
      "181 20.422136306762695\n",
      "182 19.57430648803711\n",
      "183 18.76288414001465\n",
      "184 17.985797882080078\n",
      "185 17.242385864257812\n",
      "186 16.5294246673584\n",
      "187 15.848262786865234\n",
      "188 15.195115089416504\n",
      "189 14.570036888122559\n",
      "190 13.97114372253418\n",
      "191 13.39768123626709\n",
      "192 12.848125457763672\n",
      "193 12.322226524353027\n",
      "194 11.818154335021973\n",
      "195 11.335731506347656\n",
      "196 10.873106002807617\n",
      "197 10.429537773132324\n",
      "198 10.004870414733887\n",
      "199 9.598058700561523\n",
      "200 9.208283424377441\n",
      "201 8.834415435791016\n",
      "202 8.476530075073242\n",
      "203 8.133195877075195\n",
      "204 7.804384231567383\n",
      "205 7.488985061645508\n",
      "206 7.186644554138184\n",
      "207 6.896878242492676\n",
      "208 6.618899345397949\n",
      "209 6.352554798126221\n",
      "210 6.097322940826416\n",
      "211 5.852179050445557\n",
      "212 5.617541790008545\n",
      "213 5.392457962036133\n",
      "214 5.176570415496826\n",
      "215 4.9692769050598145\n",
      "216 4.770814418792725\n",
      "217 4.580169200897217\n",
      "218 4.397525787353516\n",
      "219 4.222474575042725\n",
      "220 4.054134368896484\n",
      "221 3.8928802013397217\n",
      "222 3.7382285594940186\n",
      "223 3.589604616165161\n",
      "224 3.4469966888427734\n",
      "225 3.310147523880005\n",
      "226 3.1788887977600098\n",
      "227 3.053071975708008\n",
      "228 2.932295322418213\n",
      "229 2.8163211345672607\n",
      "230 2.704984664916992\n",
      "231 2.598242998123169\n",
      "232 2.495697021484375\n",
      "233 2.397348403930664\n",
      "234 2.3031182289123535\n",
      "235 2.2124903202056885\n",
      "236 2.1253931522369385\n",
      "237 2.041985034942627\n",
      "238 1.9618057012557983\n",
      "239 1.8849241733551025\n",
      "240 1.811052680015564\n",
      "241 1.7401398420333862\n",
      "242 1.672160267829895\n",
      "243 1.6067087650299072\n",
      "244 1.5440329313278198\n",
      "245 1.483638048171997\n",
      "246 1.4257616996765137\n",
      "247 1.3702051639556885\n",
      "248 1.3168785572052002\n",
      "249 1.2657358646392822\n",
      "250 1.216500997543335\n",
      "251 1.1692482233047485\n",
      "252 1.123849630355835\n",
      "253 1.0803232192993164\n",
      "254 1.0383387804031372\n",
      "255 0.9981563687324524\n",
      "256 0.9595962166786194\n",
      "257 0.9223719239234924\n",
      "258 0.8867444396018982\n",
      "259 0.8525077104568481\n",
      "260 0.8196097016334534\n",
      "261 0.7879178524017334\n",
      "262 0.7576474547386169\n",
      "263 0.7282971739768982\n",
      "264 0.7003551125526428\n",
      "265 0.6734498739242554\n",
      "266 0.6475694179534912\n",
      "267 0.6227059364318848\n",
      "268 0.5987783670425415\n",
      "269 0.5757109522819519\n",
      "270 0.5537111759185791\n",
      "271 0.5325450897216797\n",
      "272 0.5121387243270874\n",
      "273 0.4925571084022522\n",
      "274 0.4737066626548767\n",
      "275 0.4556036591529846\n",
      "276 0.43824347853660583\n",
      "277 0.421458899974823\n",
      "278 0.40539121627807617\n",
      "279 0.3899710178375244\n",
      "280 0.3751140236854553\n",
      "281 0.36083871126174927\n",
      "282 0.3470882475376129\n",
      "283 0.3339253067970276\n",
      "284 0.3212893009185791\n",
      "285 0.3089905381202698\n",
      "286 0.297292560338974\n",
      "287 0.2860504388809204\n",
      "288 0.2751722037792206\n",
      "289 0.26478415727615356\n",
      "290 0.2547794282436371\n",
      "291 0.24516497552394867\n",
      "292 0.23586951196193695\n",
      "293 0.22693344950675964\n",
      "294 0.21839453279972076\n",
      "295 0.21017111837863922\n",
      "296 0.20223812758922577\n",
      "297 0.1945953071117401\n",
      "298 0.18725794553756714\n",
      "299 0.18019215762615204\n",
      "300 0.17345431447029114\n",
      "301 0.16692809760570526\n",
      "302 0.1606416404247284\n",
      "303 0.154654398560524\n",
      "304 0.1488199532032013\n",
      "305 0.14320802688598633\n",
      "306 0.13784602284431458\n",
      "307 0.13273371756076813\n",
      "308 0.1277513951063156\n",
      "309 0.12299206852912903\n",
      "310 0.11840904504060745\n",
      "311 0.11397232860326767\n",
      "312 0.10968092828989029\n",
      "313 0.10561880469322205\n",
      "314 0.10168273746967316\n",
      "315 0.09788519889116287\n",
      "316 0.09425787627696991\n",
      "317 0.09072566032409668\n",
      "318 0.08733656257390976\n",
      "319 0.08412385731935501\n",
      "320 0.08097729086875916\n",
      "321 0.07796631753444672\n",
      "322 0.07506649941205978\n",
      "323 0.07229910045862198\n",
      "324 0.06964567303657532\n",
      "325 0.06705566495656967\n",
      "326 0.06458687037229538\n",
      "327 0.062160998582839966\n",
      "328 0.05989030748605728\n",
      "329 0.05768768861889839\n",
      "330 0.05556628108024597\n",
      "331 0.0535118542611599\n",
      "332 0.05153364688158035\n",
      "333 0.049623988568782806\n",
      "334 0.04780175909399986\n",
      "335 0.0460498109459877\n",
      "336 0.044360361993312836\n",
      "337 0.042730432003736496\n",
      "338 0.041171953082084656\n",
      "339 0.039656028151512146\n",
      "340 0.03819473832845688\n",
      "341 0.03680753335356712\n",
      "342 0.035459235310554504\n",
      "343 0.03416295722126961\n",
      "344 0.03290821239352226\n",
      "345 0.03171497955918312\n",
      "346 0.03055885247886181\n",
      "347 0.029447978362441063\n",
      "348 0.0283825546503067\n",
      "349 0.027353297919034958\n",
      "350 0.02636951394379139\n",
      "351 0.025410082191228867\n",
      "352 0.024503661319613457\n",
      "353 0.023608602583408356\n",
      "354 0.022743912413716316\n",
      "355 0.02192559465765953\n",
      "356 0.021139664575457573\n",
      "357 0.020375821739435196\n",
      "358 0.0196438767015934\n",
      "359 0.018933119252324104\n",
      "360 0.018259704113006592\n",
      "361 0.017605464905500412\n",
      "362 0.01698072999715805\n",
      "363 0.01636574976146221\n",
      "364 0.01579364389181137\n",
      "365 0.01523319911211729\n",
      "366 0.014691639691591263\n",
      "367 0.014163058251142502\n",
      "368 0.013658973388373852\n",
      "369 0.013168975710868835\n",
      "370 0.012706330046057701\n",
      "371 0.012261277996003628\n",
      "372 0.011826271191239357\n",
      "373 0.011409965343773365\n",
      "374 0.01101388968527317\n",
      "375 0.01062762551009655\n",
      "376 0.010256447829306126\n",
      "377 0.009899483062326908\n",
      "378 0.009557800367474556\n",
      "379 0.00922264065593481\n",
      "380 0.008899519219994545\n",
      "381 0.008597239851951599\n",
      "382 0.008299260400235653\n",
      "383 0.008016771636903286\n",
      "384 0.007743687368929386\n",
      "385 0.007478510495275259\n",
      "386 0.007218541577458382\n",
      "387 0.006976895034313202\n",
      "388 0.00673592509701848\n",
      "389 0.0065055410377681255\n",
      "390 0.006282683461904526\n",
      "391 0.0060712420381605625\n",
      "392 0.005862736608833075\n",
      "393 0.005665775388479233\n",
      "394 0.00547547172755003\n",
      "395 0.0052958400920033455\n",
      "396 0.005123479291796684\n",
      "397 0.004953265190124512\n",
      "398 0.004785601515322924\n",
      "399 0.004626566078513861\n",
      "400 0.004474891349673271\n",
      "401 0.004326776601374149\n",
      "402 0.004190121311694384\n",
      "403 0.004054063931107521\n",
      "404 0.003922580275684595\n",
      "405 0.0037953511346131563\n",
      "406 0.0036721741780638695\n",
      "407 0.003552780020982027\n",
      "408 0.003444608533754945\n",
      "409 0.0033328866120427847\n",
      "410 0.003229327965527773\n",
      "411 0.003129625925794244\n",
      "412 0.0030277061741799116\n",
      "413 0.002934811869636178\n",
      "414 0.002844384638592601\n",
      "415 0.0027556559070944786\n",
      "416 0.0026722426991909742\n",
      "417 0.0025884967762976885\n",
      "418 0.002509882440790534\n",
      "419 0.00243337987922132\n",
      "420 0.002361648716032505\n",
      "421 0.0022879918105900288\n",
      "422 0.0022206264548003674\n",
      "423 0.002154342830181122\n",
      "424 0.0020898852963000536\n",
      "425 0.0020305421203374863\n",
      "426 0.0019719835836440325\n",
      "427 0.0019140677759423852\n",
      "428 0.0018576900474727154\n",
      "429 0.0018046873155981302\n",
      "430 0.0017506919102743268\n",
      "431 0.0017034566262736917\n",
      "432 0.0016537006013095379\n",
      "433 0.0016064728843048215\n",
      "434 0.0015618690522387624\n",
      "435 0.0015171694103628397\n",
      "436 0.0014744132058694959\n",
      "437 0.0014324670191854239\n",
      "438 0.0013922593789175153\n",
      "439 0.0013532607117667794\n",
      "440 0.0013170044403523207\n",
      "441 0.0012814041692763567\n",
      "442 0.0012454886455088854\n",
      "443 0.0012120651081204414\n",
      "444 0.0011799746425822377\n",
      "445 0.0011498181847855449\n",
      "446 0.0011202712776139379\n",
      "447 0.0010877627646550536\n",
      "448 0.001060012960806489\n",
      "449 0.0010315130930393934\n",
      "450 0.0010053839068859816\n",
      "451 0.0009811484487727284\n",
      "452 0.0009544681524857879\n",
      "453 0.0009314530761912465\n",
      "454 0.0009082416072487831\n",
      "455 0.0008850705926306546\n",
      "456 0.0008619986474514008\n",
      "457 0.0008398879435844719\n",
      "458 0.0008200484444387257\n",
      "459 0.000800697656814009\n",
      "460 0.0007795603014528751\n",
      "461 0.0007609027670696378\n",
      "462 0.0007436336018145084\n",
      "463 0.0007243349100463092\n",
      "464 0.0007072154548950493\n",
      "465 0.0006905968184582889\n",
      "466 0.0006747954175807536\n",
      "467 0.0006580984918400645\n",
      "468 0.0006422734004445374\n",
      "469 0.0006274415063671768\n",
      "470 0.0006119947065599263\n",
      "471 0.0005997340776957572\n",
      "472 0.0005856745410710573\n",
      "473 0.0005730552366003394\n",
      "474 0.00055983621859923\n",
      "475 0.0005470555042847991\n",
      "476 0.0005350935971364379\n",
      "477 0.0005233229603618383\n",
      "478 0.0005120076239109039\n",
      "479 0.0005012722685933113\n",
      "480 0.0004903886001557112\n",
      "481 0.00047911680303514004\n",
      "482 0.00046918398584239185\n",
      "483 0.00045978589332662523\n",
      "484 0.0004511425213422626\n",
      "485 0.00044103359687142074\n",
      "486 0.0004315829719416797\n",
      "487 0.00042302580550312996\n",
      "488 0.00041484221583232284\n",
      "489 0.0004065668908879161\n",
      "490 0.0003987381642218679\n",
      "491 0.00039015302900224924\n",
      "492 0.0003823509905487299\n",
      "493 0.00037535754381679\n",
      "494 0.00036801883834414184\n",
      "495 0.0003611476859077811\n",
      "496 0.00035440147621557117\n",
      "497 0.00034741178387776017\n",
      "498 0.0003409488417673856\n",
      "499 0.0003349235630594194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,  10,   0,   8,   0,  11,   0,   0,   5,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   8,   0,   0,   4,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   5,   4,   4,   0,   9,  25,   0,  21,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  10,   5,   0,   1,   0,  11,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,  23, 176, 252,  97,  21,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   3,   0,  14, 190, 254, 248, 103,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   7, 111, 242, 255, 162,   5,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   2,  77, 250, 255, 196,  21,   0,   5,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   2,   3,   7,   0,\n",
       "            0,   5,  31, 200, 251, 242,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   3,   0,  10,   0,   2,   8,\n",
       "            8,  51, 216, 248, 255,  75,   5,  14,   0,   9,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   6,  11,   3,   0,  10,\n",
       "           85, 255, 250, 242, 177,  12,   4,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,  32,   0,   4,   5,   0,  29,\n",
       "          207, 251, 244, 161,   0,   0,  14,   0,  13,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  10,   0,   0,  25, 202,\n",
       "          255, 255, 241, 101,   0,   9,   0,   4,   0,   1,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  26, 245,\n",
       "          252, 248,  26,   0,   5,   2,   0,   1,   2,   6,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   9,   0,   5,  17, 205, 250,\n",
       "          255, 199,   5,   0,   4,   1,   6,   7,  23,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   5, 163, 255, 242,\n",
       "          207,   3,   2,   1,   0,   0,   2,   0,   0,   4,   0,   0,   0,   0],\n",
       "         [  3,   0,   8,   0,   0,   7,   2,   0,   0,   2,  31, 186, 255, 255,\n",
       "           52,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  4,   0,   4,   2,   0,   0,   0,   5,   6,  25, 171, 255, 246,  91,\n",
       "           14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   1,   0,   0,   6,   0,   3,   7,  92, 255, 253, 176,   2,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   4,   0,   0,  15,   0,   0,  85, 237, 255, 193,  26,   6,\n",
       "            0,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   1,   5,   0,   0,   0,   0,  23, 223, 252, 255,  71,   3,   0,\n",
       "            3,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   2,   8,   5,   0,   6,  88, 255, 255, 242, 114,   0,  18,\n",
       "            4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   1,   5,  10,   0,   8,  83, 237, 255, 252, 123,   0,   0,\n",
       "            4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  11,   5,   0,   2,   3,   0,  11, 224, 209,  91,   7,   0,   1,\n",
       "            0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "        dtype=torch.uint8)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train',\n",
    "                                           transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
